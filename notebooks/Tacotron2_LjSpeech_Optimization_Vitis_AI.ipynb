{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "encouraging-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interesting-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/workspace/open_source_work/TensorFlowTTS/dump_ljspeech/train/wavs/'\n",
    "train_wav_dir = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "roman-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib = []\n",
    "for i in range(5):\n",
    "    np_name = train_wav_dir[i]\n",
    "    np_file = np.load(path + np_name)\n",
    "    calib.append(np_file)\n",
    "calib_dataset = np.array(calib)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accredited-arnold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 0.00350952,  0.00335693,  0.00482178, ..., -0.0005188 ,\n",
       "       -0.0005188 , -0.0005188 ], dtype=float32),\n",
       "       array([ 0.00268555,  0.00228882,  0.00143433, ..., -0.00079346,\n",
       "       -0.00079346, -0.00079346], dtype=float32),\n",
       "       array([-1.5258789e-04,  3.0517578e-05,  6.1035156e-05, ...,\n",
       "        9.1552734e-05,  9.1552734e-05,  9.1552734e-05], dtype=float32),\n",
       "       array([-3.0517578e-05, -9.1552734e-05, -6.1035156e-05, ...,\n",
       "        3.0517578e-05,  3.0517578e-05,  3.0517578e-05], dtype=float32)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calib_dataset[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-browse",
   "metadata": {},
   "source": [
    "## Vitis-AI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "palestinian-wings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._2_layer_call_and_return_conditional_losses_10690) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._1_layer_call_and_return_conditional_losses_31114) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._3_layer_call_and_return_conditional_losses_31344) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._3_layer_call_and_return_conditional_losses_17482) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._2_layer_call_and_return_conditional_losses_31229) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._3_layer_call_and_return_conditional_losses_10896) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._1_layer_call_and_return_conditional_losses_17070) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._2_layer_call_and_return_conditional_losses_30654) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._1_layer_call_and_return_conditional_losses_30539) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._0_layer_call_and_return_conditional_losses_30999) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._4_layer_call_and_return_conditional_losses_17688) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._3_layer_call_and_return_conditional_losses_30769) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._2_layer_call_and_return_conditional_losses_17276) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._4_layer_call_and_return_conditional_losses_30884) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._4_layer_call_and_return_conditional_losses_31459) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._4_layer_call_and_return_conditional_losses_11102) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._0_layer_call_and_return_conditional_losses_10278) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._0_layer_call_and_return_conditional_losses_16864) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._0_layer_call_and_return_conditional_losses_30424) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_batch_norm_._1_layer_call_and_return_conditional_losses_10484) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.saving.saved_model.load.SavableTFTacotron2 at 0x7fb6f00bbb50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tacotron2_model_path = './tacotron2_saved_model_english'\n",
    "model = tf.keras.models.load_model(tacotron2_model_path)\n",
    " \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "attended-shelter",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only tf.keras sequential or functional models can be transformed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d16b30808f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mquantizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvitis_quantize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVitisQuantizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mquantized_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalib_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalib_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/vitis/vitis_quantize.py\u001b[0m in \u001b[0;36mquantize_model\u001b[0;34m(self, loss, metrics, calib_dataset, eval_dataset, verbose, remove_dropout, fold_conv_bn, fold_bn, replace_relu6, include_cle, cle_steps)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     self.optimize_model(remove_dropout, fold_conv_bn, fold_bn, replace_relu6,\n\u001b[0;32m--> 653\u001b[0;31m                         include_cle, cle_steps)\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qcb_model\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qcbev_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/vitis/vitis_quantize.py\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m(self, remove_dropout, fold_conv_bn, fold_bn, replace_relu6, include_cle, cle_steps)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimized_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m       self._create_optimized_model(remove_dropout, fold_conv_bn, fold_bn,\n\u001b[0;32m--> 605\u001b[0;31m                                    replace_relu6, include_cle, cle_steps)\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimized_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/vitis/vitis_quantize.py\u001b[0m in \u001b[0;36m_create_optimized_model\u001b[0;34m(self, remove_dropout, fold_conv_bn, fold_bn, replace_relu6, include_cle, cle_steps)\u001b[0m\n\u001b[1;32m    314\u001b[0m                                                      \u001b[0mfold_conv_bn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_bn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                                                      \u001b[0mreplace_relu6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_cle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                                                      cle_steps)\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_analysed_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/vitis/vitis_quantize.py\u001b[0m in \u001b[0;36mcreate_optimize_model\u001b[0;34m(model, layer_quantize_map, remove_dropout, fold_conv_bn, fold_bn, replace_relu6, include_cle, cle_steps)\u001b[0m\n\u001b[1;32m    687\u001b[0m   optimized_model, layer_quantize_map = optimize_transform.apply(\n\u001b[1;32m    688\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_quantize_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_conv_bn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_bn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       replace_relu6, include_cle, cle_steps)\n\u001b[0m\u001b[1;32m    690\u001b[0m   \u001b[0;31m#  optimized_model.save('optimized.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moptimized_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_quantize_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/vitis/vitis_8bit_quantize_layout_transform.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, model, layer_quantize_map, remove_dropout, fold_conv_bn, fold_bn, replace_relu6, include_cle, cle_steps)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     transformed_model, layer_quantize_map = model_transformer.ModelTransformer(\n\u001b[0;32m---> 58\u001b[0;31m         model, transforms, None, layer_quantize_map).transform()\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Cross Layer Equalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/quantization/keras/vitis/graph_transformations/model_transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, transforms, candidate_layers, layer_metadata)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_sequential_or_functional_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m       raise ValueError(\n\u001b[0;32m---> 53\u001b[0;31m           'Only tf.keras sequential or functional models can be transformed.')\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayer_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only tf.keras sequential or functional models can be transformed."
     ]
    }
   ],
   "source": [
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "\n",
    "quantizer = vitis_quantize.VitisQuantizer(model)\n",
    "\n",
    "quantized_model = quantizer.quantize_model(calib_dataset = calib_dataset[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "quantized_model.save(save_dir + 'vitis-ai-quantized_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vai_c_tensorflow2 -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vai_c_tensorflow2 -m mnist-results/vitis-ai-quantized_mnist_model.h5 -o mnist-results/ -n mnist_XIR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
